{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bored-persian",
   "metadata": {},
   "source": [
    "# Practice Querying the Snowexsql Database\n",
    "\n",
    "(12 minutes)\n",
    "\n",
    "Learning Objectives:  \n",
    "- First taste of the database!\n",
    "- Code snippets to extract and prep data.\n",
    "- Generate ideas for project pitches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "executive-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import datetime\n",
    "\n",
    "#database imports\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import PointData, LayerData, ImageData, SiteData\n",
    "from snowexsql.conversions import query_to_geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorrect-coating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snowexsql database successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "# load the database\n",
    "db_name = 'snow:hackweek@52.32.183.144/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "print('snowexsql database successfully loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-authority",
   "metadata": {},
   "source": [
    "## Snow Pit data are contained in the following data tables:  \n",
    "\n",
    "_PointData_  = pit ruler depths, SWE.  \n",
    "_LayerData_  = density, temperature, stratigraphy, etc.  \n",
    "_SiteData_   = siteID, airTemp, vegetation, visit time, weather, etc.  \n",
    "\n",
    "### Example 1: Let's find all the pits that overlap with an airborne sensor of interest!\n",
    "\n",
    "First, it would be helpful to know, which of the airborne sensors are part of the database, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abstract-harassment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of airborne sensors by \"surveyor\" name: \n",
      " [('USGS',), ('UAVSAR team, JPL',), ('ASO Inc.',)]\n"
     ]
    }
   ],
   "source": [
    "# Query the session using .surveyors() to generate a list\n",
    "qry = session.query(ImageData.surveyors)\n",
    "\n",
    "# Locate all that are distinct\n",
    "airborne_sensors_list = session.query(ImageData.surveyors).distinct().all()\n",
    "\n",
    "print('list of airborne sensors by \"surveyor\" name: \\n', airborne_sensors_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-thomas",
   "metadata": {},
   "source": [
    "#### 1a). Unsure of the flight date, but know which sensor you'd like to overlap with, here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "academic-offering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAVSAR team, JPL flight dates are: 2020-01-31, 2020-02-12\n"
     ]
    }
   ],
   "source": [
    "# airborne sensor from list above\n",
    "sensor = 'UAVSAR team, JPL'\n",
    "\n",
    "# Form on the Images table that returns Raster collection dates\n",
    "qry = session.query(ImageData.date)\n",
    "\n",
    "# Filter for UAVSAR data\n",
    "qry = qry.filter(ImageData.surveyors == sensor)\n",
    "\n",
    "# Grab the unique dates\n",
    "qry = qry.distinct()\n",
    "\n",
    "# Execute the query \n",
    "dates = qry.all() \n",
    "\n",
    "# Clean up the dates \n",
    "dates = [d[0] for d in dates] \n",
    "dlist = [str(d) for d in dates]\n",
    "dlist = \", \".join(dlist)\n",
    "print('%s flight dates are: %s' %(sensor, dlist))\n",
    "\n",
    "# Find all the snow pits done on these days\n",
    "qry = session.query(SiteData.geom, SiteData.site_id, SiteData.date)\n",
    "qry = qry.filter(SiteData.date.in_(dates))\n",
    "\n",
    "# return a geopandas df\n",
    "df = query_to_geopandas(qry, engine)\n",
    "df.head()\n",
    "\n",
    "# Close your session to avoid hanging transactions\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-escape",
   "metadata": {},
   "source": [
    "#### 1b). Want to select an exact flight date match? Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "metric-grove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 pits overlap with UAVSAR team, JPL on 2020-01-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geom</th>\n",
       "      <th>site_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (740652.000 4327445.000)</td>\n",
       "      <td>2C2</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (744396.000 4323540.000)</td>\n",
       "      <td>8C26</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (741960.000 4326644.000)</td>\n",
       "      <td>6C10</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (741493.000 4326833.000)</td>\n",
       "      <td>1C8</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (745340.000 4322754.000)</td>\n",
       "      <td>8S28</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             geom site_id        date\n",
       "0  POINT (740652.000 4327445.000)     2C2  2020-01-31\n",
       "1  POINT (744396.000 4323540.000)    8C26  2020-01-31\n",
       "2  POINT (741960.000 4326644.000)    6C10  2020-01-31\n",
       "3  POINT (741493.000 4326833.000)     1C8  2020-01-31\n",
       "4  POINT (745340.000 4322754.000)    8S28  2020-01-31"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick a day from the list of dates\n",
    "dt = dates[0] \n",
    "\n",
    "# Find all the snow pits done on these days \n",
    "qry = session.query(SiteData.geom, SiteData.site_id, SiteData.date)\n",
    "qry = qry.filter(SiteData.date == dt)\n",
    "\n",
    "# return a geopandas df\n",
    "df_exact = query_to_geopandas(qry, engine)\n",
    "\n",
    "print('%s pits overlap with %s on %s' %(len(df_exact), sensor, dt))\n",
    "df_exact.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mature-relationship",
   "metadata": {},
   "source": [
    "#### 1c). Want to select a range of dates near the flight date? Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "virgin-innocent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 pits overlap with UAVSAR team, JPL on 2020-01-30, 2020-01-31, 2020-02-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geom</th>\n",
       "      <th>site_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POINT (744561.000 4322721.000)</td>\n",
       "      <td>5S21</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POINT (746228.000 4322671.000)</td>\n",
       "      <td>9S39</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POINT (745937.000 4322754.000)</td>\n",
       "      <td>2S37</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POINT (746546.000 4324066.000)</td>\n",
       "      <td>8N45</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POINT (746350.000 4321976.000)</td>\n",
       "      <td>6C34</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>POINT (746149.000 4322488.000)</td>\n",
       "      <td>3S38</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>POINT (743652.000 4322680.000)</td>\n",
       "      <td>3S14</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>POINT (747055.000 4323916.000)</td>\n",
       "      <td>5N50</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>POINT (746553.000 4323759.000)</td>\n",
       "      <td>6N46</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>POINT (746303.000 4322571.000)</td>\n",
       "      <td>9S40</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>POINT (745842.000 4323805.000)</td>\n",
       "      <td>9N44</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>POINT (746802.000 4324222.000)</td>\n",
       "      <td>2N48</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>POINT (743109.000 4322924.000)</td>\n",
       "      <td>2S11</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>POINT (742607.000 4322917.000)</td>\n",
       "      <td>1S8</td>\n",
       "      <td>2020-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>POINT (740652.000 4327445.000)</td>\n",
       "      <td>2C2</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>POINT (744396.000 4323540.000)</td>\n",
       "      <td>8C26</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>POINT (741960.000 4326644.000)</td>\n",
       "      <td>6C10</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>POINT (741493.000 4326833.000)</td>\n",
       "      <td>1C8</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>POINT (745340.000 4322754.000)</td>\n",
       "      <td>8S28</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>POINT (744862.000 4323250.000)</td>\n",
       "      <td>4C30</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>POINT (742466.000 4324372.000)</td>\n",
       "      <td>2N12</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>POINT (744477.000 4323731.000)</td>\n",
       "      <td>8C22</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>POINT (740765.000 4327379.000)</td>\n",
       "      <td>2C3</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>POINT (741378.000 4326992.000)</td>\n",
       "      <td>1C7</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POINT (740508.000 4327577.000)</td>\n",
       "      <td>1C1</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>POINT (744757.000 4323667.000)</td>\n",
       "      <td>6C24</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>POINT (741132.000 4327061.000)</td>\n",
       "      <td>2C6</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>POINT (742453.000 4325752.000)</td>\n",
       "      <td>1C14</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>POINT (740839.000 4327345.000)</td>\n",
       "      <td>2C4</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>POINT (741580.000 4326713.000)</td>\n",
       "      <td>2C9</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>POINT (745010.000 4323372.000)</td>\n",
       "      <td>9C28</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>POINT (743817.000 4324185.000)</td>\n",
       "      <td>4N27</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>POINT (743446.000 4324827.000)</td>\n",
       "      <td>9C19</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>POINT (743402.000 4324736.000)</td>\n",
       "      <td>5C20</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>POINT (745598.000 4323988.000)</td>\n",
       "      <td>5N41</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>POINT (743040.000 4324967.000)</td>\n",
       "      <td>9C17</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>POINT (744913.000 4324095.000)</td>\n",
       "      <td>8N34</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>POINT (744625.000 4323947.000)</td>\n",
       "      <td>6N31</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>POINT (744281.000 4324245.000)</td>\n",
       "      <td>9N29</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>POINT (743884.000 4324477.000)</td>\n",
       "      <td>5C21</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>POINT (744548.000 4323646.000)</td>\n",
       "      <td>8C25</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>POINT (745121.000 4324175.000)</td>\n",
       "      <td>6N36</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>POINT (745305.000 4323998.000)</td>\n",
       "      <td>8N38</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>POINT (745678.000 4322446.000)</td>\n",
       "      <td>2S35</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>POINT (745458.000 4322762.000)</td>\n",
       "      <td>5S31</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>POINT (742674.000 4325582.000)</td>\n",
       "      <td>7C15</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>POINT (745787.000 4322066.000)</td>\n",
       "      <td>2C33</td>\n",
       "      <td>2020-01-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              geom site_id        date\n",
       "0   POINT (744561.000 4322721.000)    5S21  2020-02-01\n",
       "1   POINT (746228.000 4322671.000)    9S39  2020-02-01\n",
       "2   POINT (745937.000 4322754.000)    2S37  2020-02-01\n",
       "3   POINT (746546.000 4324066.000)    8N45  2020-02-01\n",
       "4   POINT (746350.000 4321976.000)    6C34  2020-02-01\n",
       "5   POINT (746149.000 4322488.000)    3S38  2020-02-01\n",
       "6   POINT (743652.000 4322680.000)    3S14  2020-02-01\n",
       "7   POINT (747055.000 4323916.000)    5N50  2020-02-01\n",
       "8   POINT (746553.000 4323759.000)    6N46  2020-02-01\n",
       "9   POINT (746303.000 4322571.000)    9S40  2020-02-01\n",
       "10  POINT (745842.000 4323805.000)    9N44  2020-02-01\n",
       "11  POINT (746802.000 4324222.000)    2N48  2020-02-01\n",
       "12  POINT (743109.000 4322924.000)    2S11  2020-02-01\n",
       "13  POINT (742607.000 4322917.000)     1S8  2020-02-01\n",
       "14  POINT (740652.000 4327445.000)     2C2  2020-01-31\n",
       "15  POINT (744396.000 4323540.000)    8C26  2020-01-31\n",
       "16  POINT (741960.000 4326644.000)    6C10  2020-01-31\n",
       "17  POINT (741493.000 4326833.000)     1C8  2020-01-31\n",
       "18  POINT (745340.000 4322754.000)    8S28  2020-01-31\n",
       "19  POINT (744862.000 4323250.000)    4C30  2020-01-31\n",
       "20  POINT (742466.000 4324372.000)    2N12  2020-01-31\n",
       "21  POINT (744477.000 4323731.000)    8C22  2020-01-31\n",
       "22  POINT (740765.000 4327379.000)     2C3  2020-01-31\n",
       "23  POINT (741378.000 4326992.000)     1C7  2020-01-31\n",
       "24  POINT (740508.000 4327577.000)     1C1  2020-01-31\n",
       "25  POINT (744757.000 4323667.000)    6C24  2020-01-31\n",
       "26  POINT (741132.000 4327061.000)     2C6  2020-01-31\n",
       "27  POINT (742453.000 4325752.000)    1C14  2020-01-31\n",
       "28  POINT (740839.000 4327345.000)     2C4  2020-01-31\n",
       "29  POINT (741580.000 4326713.000)     2C9  2020-01-31\n",
       "30  POINT (745010.000 4323372.000)    9C28  2020-01-31\n",
       "31  POINT (743817.000 4324185.000)    4N27  2020-01-30\n",
       "32  POINT (743446.000 4324827.000)    9C19  2020-01-30\n",
       "33  POINT (743402.000 4324736.000)    5C20  2020-01-30\n",
       "34  POINT (745598.000 4323988.000)    5N41  2020-01-30\n",
       "35  POINT (743040.000 4324967.000)    9C17  2020-01-30\n",
       "36  POINT (744913.000 4324095.000)    8N34  2020-01-30\n",
       "37  POINT (744625.000 4323947.000)    6N31  2020-01-30\n",
       "38  POINT (744281.000 4324245.000)    9N29  2020-01-30\n",
       "39  POINT (743884.000 4324477.000)    5C21  2020-01-30\n",
       "40  POINT (744548.000 4323646.000)    8C25  2020-01-30\n",
       "41  POINT (745121.000 4324175.000)    6N36  2020-01-30\n",
       "42  POINT (745305.000 4323998.000)    8N38  2020-01-30\n",
       "43  POINT (745678.000 4322446.000)    2S35  2020-01-30\n",
       "44  POINT (745458.000 4322762.000)    5S31  2020-01-30\n",
       "45  POINT (742674.000 4325582.000)    7C15  2020-01-30\n",
       "46  POINT (745787.000 4322066.000)    2C33  2020-01-30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Form a date range to query on either side of our chosen day \n",
    "date_range = [dt + i * datetime.timedelta(days=1) for i in [-1, 0, 1]]\n",
    "\n",
    "# Find all the snow pits done on these days and return a geopandas df\n",
    "qry = session.query(SiteData.geom, SiteData.site_id, SiteData.date)\n",
    "qry = qry.filter(SiteData.date.in_(date_range))\n",
    "\n",
    "# return a geopandas df\n",
    "df_range = query_to_geopandas(qry, engine)\n",
    "\n",
    "# clean up dates (for print statement only)\n",
    "dlist = [str(d) for d in date_range]\n",
    "dlist = \", \".join(dlist)\n",
    "\n",
    "print('%s pits overlap with %s on %s' %(len(df_range), sensor, dlist))\n",
    "df_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-finnish",
   "metadata": {},
   "source": [
    "#### 1d). Have a known date in mind that you wish to select data for, here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sufficient-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point Data on %s are: \n",
      "%s ('2020-02-12', [('camera-trap',), ('magnaprobe',), ('pit ruler',)])\n",
      "\n",
      "Layer Data are: \n",
      " [('IRIS', 'equivalent_diameter'), ('IRIS', 'reflectance'), ('IRIS', 'sample_signal'), ('IRIS', 'specific_surface_area'), ('IS3-SP-11-01F', 'equivalent_diameter'), ('IS3-SP-11-01F', 'reflectance'), ('IS3-SP-11-01F', 'sample_signal'), ('IS3-SP-11-01F', 'specific_surface_area'), ('snowmicropen', 'force'), (None, 'density'), (None, 'grain_size'), (None, 'grain_type'), (None, 'hand_hardness'), (None, 'lwc_vol'), (None, 'manual_wetness'), (None, 'permittivity'), (None, 'temperature')]\n",
      "\n",
      "Image Data are: \n",
      " [('UAVSAR, L-band InSAR',)]\n"
     ]
    }
   ],
   "source": [
    "# Find all the data that was collected on 2-12-2020\n",
    "dt = datetime.date(2020, 2, 12)\n",
    "\n",
    "# Grab all Point data instruments from our date\n",
    "point_instruments = session.query(PointData.instrument).filter(PointData.date == dt).distinct().all()\n",
    "print('Point Data on %s are: \\n%s', (str(dt), point_instruments))\n",
    "\n",
    "# Grab all Layer data instruments from our date\n",
    "layer_instruments = session.query(LayerData.instrument, LayerData.type).filter(LayerData.date == dt).distinct().all()\n",
    "print('\\nLayer Data are: \\n', layer_instruments)\n",
    "\n",
    "# Grab all Image data instruments from our date\n",
    "image_instruments = session.query(ImageData.instrument).filter(ImageData.date == dt).distinct().all()\n",
    "print('\\nImage Data are: \\n', image_instruments)\n",
    "\n",
    "qry = session.query(PointData.geom, PointData.instrument, PointData.site_id, PointData.date)\n",
    "qry = qry.filter(PointData.date == dt) \n",
    "df = query_to_geopandas(qry, engine)\n",
    "df\n",
    "\n",
    "qry = session.query(LayerData.geom, LayerData.instrument, LayerData.site_id, LayerData.date)\n",
    "qry = qry.filter(LayerData.date == dt) \n",
    "df = query_to_geopandas(qry, engine)\n",
    "df\n",
    "\n",
    "qry = session.query(ImageData.instrument, ImageData.site_id, ImageData.date)\n",
    "qry = qry.filter(ImageData.date == dt) \n",
    "qry = qry.distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "operational-thirty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-02-12'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "str(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-color",
   "metadata": {},
   "source": [
    "### Nice work, almost done here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-freedom",
   "metadata": {},
   "source": [
    "## Classify pit data based on the depth and vegetation matrix\n",
    "### Example 2: \n",
    "\n",
    "#### 2a).Distinguish pits by vegetation coverage: \n",
    "- treeless (0% tree cover)\n",
    "- sparse (1-30% tree cover)\n",
    "- dense (31-100% tree cover)\n",
    "\n",
    "*vegetation classes assigned based on optical imagery: tree density map, Nov. 2010 WorldView-2 Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_veg_class(site_id):\n",
    "    \n",
    "        '''\n",
    "    This function parses snow pit data into three vegetation classes:\n",
    "        - 1). Treeless, 2). Sparce, and 3). Dense\n",
    "        \n",
    "    It uses a python dictionary where:\n",
    "        (k) keys: are the vegetation classes\n",
    "        (v) values: are the first digit in the pitID assignment\n",
    "\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Classifying by vegetation coverage \n",
    "    veg_class = {'treeless':[1, 2, 3], 'sparse':[4, 5, 6], 'dense':[7, 8, 9]}\n",
    "   \n",
    "    vclass = None \n",
    "    \n",
    "    class_id = site_id[0]\n",
    "    \n",
    "    if class_id.isnumeric():\n",
    "        class_id = int(class_id)\n",
    "\n",
    "        for k,v in veg_class.items():\n",
    "\n",
    "            if class_id in v: #if the first digit in the site_id is 'v' assign it to the corresponding 'k'\n",
    "                vclass = k \n",
    "                \n",
    "    return vclass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-complement",
   "metadata": {},
   "source": [
    "#### 2b). Distinguish pits by snow depth classes: \n",
    "- shallow (<90cm)\n",
    "- medium (90-122cm)\n",
    "- deep (>122cm)\n",
    "\n",
    "*depth classes assigned based on 2017 snow depth lidar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_depth_class(site_id):\n",
    "    \n",
    "            '''\n",
    "    This function parses snow pit data into three depth classes:\n",
    "        - 1). Shallow, 2). Medium, and 3). Deep\n",
    "        \n",
    "    It uses a python dictionary where:\n",
    "        (k) keys: are the depth classes\n",
    "        (v) values: are the first digit in the pitID assignment\n",
    "      \n",
    "  \n",
    "    '''\n",
    "        \n",
    "    # Classifying by expected depth \n",
    "    depth_class = {'shallow':[1, 4, 7], 'medium':[2, 5, 8], 'deep':[3, 6, 9]} \n",
    "   \n",
    "    dclass = None \n",
    "    \n",
    "    class_id = site_id[0]\n",
    "    \n",
    "    if class_id.isnumeric(): #for the outlier TS site\n",
    "        class_id = int(class_id) #cast as integer\n",
    "\n",
    "        for k,v in depth_class.items(): #for the key, value pairs in the dict listed above:\n",
    "\n",
    "            if class_id in v: #if the first digit in the site_id is 'v' assign it to the corresponding 'k'\n",
    "                dclass = k \n",
    "\n",
    "    return dclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-plymouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the database\n",
    "db_name = 'snow:hackweek@52.32.183.144/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "result = session.query(LayerData.type).distinct().all()\n",
    "\n",
    "qry = session.query(LayerData).filter(LayerData.type=='density')\n",
    "\n",
    "# Form our dataframe from the query \n",
    "df = query_to_geopandas(qry, engine)\n",
    "df['value'] = df['value'].astype(float) #cast the value as a float (they are strings)\n",
    " \n",
    "# parse snow pit data by the veg/depth matrix\n",
    "df['veg_class'] = [parse_veg_class(i) for i in df['site_id']] #run the parse_veg function for every site_id\n",
    "df['depth_class'] = [parse_depth_class(i) for i in df['site_id']] #run the parse_depth funciton for every site_id\n",
    "\n",
    "# # Show off our df \n",
    "# df.plot()\n",
    "\n",
    "df.columns\n",
    "col_list = ['site_name', 'date', 'id', 'instrument', 'type', 'units', 'surveyors', 'latitude',\n",
    "       'longitude', 'geom','depth', 'site_id', 'value', 'veg_class', 'depth_class']\n",
    "df = df[col_list]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all of the unique site ids \n",
    "len(df['site_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make df with only 153 rows using site_id.unique\n",
    "gb = df.groupby(['site_id', 'veg_class'])\n",
    "#gb = df.groupby('site_id')\n",
    "gb['site_name'].count().groupby(\"veg_class\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = df[['veg_class', 'depth_class']].groupby(df['site_id']).groups\n",
    "# gb = df.groupby(['veg_class', 'site_id']).count()\n",
    "# gb = df.groupby(['site_id']).count()\n",
    "# df['veg_class'].groupby('veg_class').count()\n",
    "\n",
    "# print(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['site_id'].unique().groupby('veg_class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['veg_class', 'site_id']].groupby('veg_class').count() #table I like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great for debugging especially when trying different queries\n",
    "# session.rollback()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
