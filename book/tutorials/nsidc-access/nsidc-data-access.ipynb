{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing SnowEx Data at the NSIDC DAAC\n",
    "\n",
    "2021 SnowEx Hackweek\n",
    "\n",
    "Author: Amy Steiker, NSIDC DAAC, CIRES, University of Colorado\n",
    "\n",
    "\n",
    "This tutorial provides a brief overview of the resources provided by the NASA National Snow and Ice Data Center Distributed Active Archive Center, or NSIDC DAAC, and demonstrates how to access SnowEx data across several methods.  \n",
    "\n",
    "## Learning Objectives:\n",
    "\n",
    "1. Identify resources available at the NSIDC DAAC to help you work with SnowEx data. \n",
    "2. Search and discover file size and coverage of SnowEx data over a time and geojson region of interest.\n",
    "3. Set up Earthdata Login authentication.\n",
    "4. Download SnowEx data programmatically using the NSIDC DAAC API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Explore snow products and resources\n",
    "\n",
    "\n",
    "### NSIDC introduction\n",
    "\n",
    "[The National Snow and Ice Data Center](https://nsidc.org), located in Boulder, Colorado, provides over 1100 data sets covering the Earth's cryosphere and more, all of which are available to the public free of charge. Beyond providing these data, NSIDC creates tools for data access, supports data users, performs scientific research, and educates the public about the cryosphere. \n",
    "\n",
    "<img align=\"left\" src=\"nsidc-daac-header.png\">\n",
    "\n",
    "The [NASA National Snow and Ice Data Center Distributed Active Archive Center (NSIDC DAAC)](https://nsidc.org/daac) provides access to over 700 data products (over 2 PB of data and growing!) in support of cryospheric research, global change detection, and water resource management. NSIDC is one of 12 DAACs as part of NASA’s EOSDIS, or Earth Observing System Data and Information System, and is also the largest program within the National Snow and Ice Data Center, as part of the University of Colorado’s Cooperative Institute for Research in Environmental Sciences. \n",
    "\n",
    "\n",
    "#### Select Data Resources\n",
    "\n",
    "* [NSIDC Data Search](https://nsidc.org/data/search/#keywords=snow)\n",
    "    * Search NSIDC snow data\n",
    "* [NSIDC Data Update Announcements](https://nsidc.org/the-drift/data-update/) \n",
    "    * News and tips for data users\n",
    "* [NASA Earthdata Search](http://search.earthdata.nasa.gov/)\n",
    "    * Search and access data across the NASA Earthdata\n",
    "* [NASA Worldview](https://worldview.earthdata.nasa.gov/)\n",
    "    * Interactive interface for browsing full-resolution, global, daily satellite images\n",
    "    \n",
    "\n",
    "\n",
    "#### Snow Today\n",
    "\n",
    "[Snow Today](https://nsidc.org/snow-today), a collaboration with the University of Colorado's Institute of Alpine and Arctic Research (INSTAAR), provides near-real-time snow analysis for the western United States and regular reports on conditions during the winter season. Snow Today is funded by NASA Hydrological Sciences Program and utilizes data from the Moderate Resolution Imaging Spectroradiometer (MODIS) instrument and snow station data from the Snow Telemetry (SNOTEL) network by the Natural Resources Conservation Service (NRCS), United States Department of Agriculture (USDA) and the California Department of Water Resources: www.wcc.nrcs.usda.gov/snow.\n",
    "\n",
    "#### NSIDC's SnowEx pages\n",
    "\n",
    "* [SnowEx](https://nsidc.org/data/snowex)\n",
    "    * We will be using the 'SnowEx17 Ground Penetrating Radar, Version 2' dataset in the following steps: https://doi.org/10.5067/G21LGCNLFSC5\n",
    "\n",
    "#### Other relevant snow products:\n",
    "\n",
    "* [ASO Snow Data](https://nsidc.org/data/search/#keywords=aso/sortKeys=score,,desc/facetFilters=%257B%2522facet_parameter%2522%253A%255B%2522SNOW%2520DEPTH%2522%252C%2522SNOW%2520WATER%2520EQUIVALENT%2522%255D%257D/pageNumber=1/itemsPerPage=25)\n",
    "\n",
    "* [MODIS Snow Data](https://nsidc.org/data/search/#sortKeys=score,,desc/facetFilters=%257B%2522facet_parameter%2522%253A%255B%2522SNOW%2520COVER%2522%252C%2522Snow%2520Cover%2522%252C%2522SNOW%2520WATER%2520EQUIVALENT%2522%252C%2522SNOW%2520DEPTH%2522%252C%2522SNOW%2520MELT%2522%252C%2522SNOW%2520VOLUME%2520BUDGET%2522%252C%2522SNOW%252FICE%2522%255D%252C%2522facet_sensor%2522%253A%255B%2522%2520%257C%2520MODIS%2522%252C%2522Moderate-Resolution%2520Imaging%2520Spectroradiometer%2520%257C%2520MODIS%2522%255D%252C%2522facet_sponsored_program%2522%253A%255B%2522NASA%2520National%2520Snow%2520and%2520Ice%2520Data%2520Center%2520Distributed%2520Active%2520Archive%2520Center%2520%257C%2520NASA%2520NSIDC%2520DAAC%2522%255D%257D/pageNumber=1/itemsPerPage=25)\n",
    "\n",
    "* [VIIRS Snow Data](http://nsidc.org/data/search/#sortKeys=score,,desc/facetFilters=%257B%2522facet_sensor%2522%253A%255B%2522Visible-Infrared%2520Imager-Radiometer%2520Suite%2520%257C%2520VIIRS%2522%255D%252C%2522facet_parameter%2522%253A%255B%2522SNOW%2520COVER%2522%252C%2522Snow%2520Cover%2522%255D%257D/pageNumber=1/itemsPerPage=25)\n",
    "\n",
    "* [AMSR-E and AMSR-E/AMSR2 Unified Snow Data](http://nsidc.org/data/search/#sortKeys=score,,desc/facetFilters=%257B%2522facet_sensor%2522%253A%255B%2522Advanced%2520Microwave%2520Scanning%2520Radiometer-EOS%2520%257C%2520AMSR-E%2522%252C%2522Advanced%2520Microwave%2520Scanning%2520Radiometer%25202%2520%257C%2520AMSR2%2522%255D%252C%2522facet_parameter%2522%253A%255B%2522SNOW%2520WATER%2520EQUIVALENT%2522%252C%2522Snow%2520Water%2520Equivalent%2522%255D%257D/pageNumber=1/itemsPerPage=25)\n",
    "\n",
    "* [MEaSUREs Snow Data](http://nsidc.org/data/search/#keywords=measures/sortKeys=score,,desc/facetFilters=%257B%2522facet_parameter%2522%253A%255B%2522SNOW%2520COVER%2522%255D%252C%2522facet_sponsored_program%2522%253A%255B%2522NASA%2520National%2520Snow%2520and%2520Ice%2520Data%2520Center%2520Distributed%2520Active%2520Archive%2520Center%2520%257C%2520NASA%2520NSIDC%2520DAAC%2522%255D%252C%2522facet_format%2522%253A%255B%2522NetCDF%2522%255D%252C%2522facet_temporal_duration%2522%253A%255B%252210%252B%2520years%2522%255D%257D/pageNumber=1/itemsPerPage=25)\n",
    "  \n",
    "* Near-Real-Time SSM/I-SSMIS EASE-Grid Daily Global Ice Concentration and Snow Extent (NISE), Version 5: https://doi.org/10.5067/3KB2JPLFPK3R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Import Packages\n",
    "\n",
    "Get started by importing packages needed to run the following code blocks, including the `tutorial_helper_functions` module provided within this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, mapping\n",
    "from shapely.geometry.polygon import orient\n",
    "import pandas as pd \n",
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import getpass\n",
    "from netrc import netrc\n",
    "from platform import system\n",
    "from getpass import getpass\n",
    "from urllib import request\n",
    "from http.cookiejar import CookieJar\n",
    "from os.path import join, expanduser\n",
    "import requests\n",
    "from xml.etree import ElementTree as ET\n",
    "import time\n",
    "import zipfile\n",
    "import io\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "\n",
    "## Data Discovery\n",
    "\n",
    "Start by identifying your study area and exploring coincident data over the same time and area. \n",
    "\n",
    "NASA Earthdata Search can be used to visualize file coverage over multiple data sets of interest: \n",
    "https://search.earthdata.nasa.gov/projects?projectId=5366449248\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify area and time of interest\n",
    "\n",
    "Since our focus is on the Grand Mesa study site of the NASA SnowEx campaign, we'll use that area to search for coincident data across other data products. From the [SnowEx17 Ground Penetrating Radar Version 2](https://doi.org/10.5067/G21LGCNLFSC5) landing page, you can find the rectangular spatial coverage under the Overview tab, or you can draw a polygon over your area of interest in the map under the Download Data tab and export the shape as a geojson file using the Export Polygon icon shown below. An example polygon geojson file is provided in the /Data folder of this repository.   \n",
    "\n",
    "<img align=\"left\" src=\"Data-download-polygon-export.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create polygon coordinate string\n",
    "\n",
    "Read in the geojson file as a GeoDataFrame object and simplify and reorder using the shapely package. This will be converted back to a dictionary to be applied as our polygon search parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygon coordinates to be used in search: -108.2352445938561,38.98556907427165,-107.85284607930835,38.978765032966244,-107.85494925720668,39.10596902171742,-108.22772795408136,39.11294532581687,-108.2352445938561,38.98556907427165\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"-108.250540534438 38.96346909238434 0.41299039571156015 0.16477217401443767\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,78.0917103587831)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"0.008259807914231204\" opacity=\"0.6\" d=\"M -108.2352445938561,38.98556907427165 L -107.85284607930835,38.978765032966244 L -107.85494925720668,39.10596902171742 L -108.22772795408136,39.11294532581687 L -108.2352445938561,38.98556907427165 z\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.polygon.Polygon at 0x7f01e88a1550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon_filepath = str(os.getcwd() + '/Data/nsidc-polygon.json') # Note: A shapefile or other vector-based spatial data format could be substituted here.\n",
    "\n",
    "gdf = gpd.read_file(polygon_filepath) #Return a GeoDataFrame object\n",
    "\n",
    "# Simplify polygon for complex shapes in order to pass a reasonable request length to CMR. The larger the tolerance value, the more simplified the polygon.\n",
    "# Orient counter-clockwise: CMR polygon points need to be provided in counter-clockwise order. The last point should match the first point to close the polygon.\n",
    "poly = orient(gdf.simplify(0.05, preserve_topology=False).loc[0],sign=1.0)\n",
    "\n",
    "#Format dictionary to polygon coordinate pairs for CMR polygon filtering\n",
    "polygon = ','.join([str(c) for xy in zip(*poly.exterior.coords.xy) for c in xy])\n",
    "print('Polygon coordinates to be used in search:', polygon)\n",
    "poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set time range\n",
    "\n",
    "This is an optional parameter; set this to specify a time range of interest. In this case we'll just select all of 2017 to ensure that we receive all files within this data set campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal = '2017-01-01T00:00:00Z,2017-12-31T23:59:59Z' # Set temporal range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data parameter dictionary \n",
    "\n",
    "Create a dictionary with the data set shortname and version, as well as the temporal range and polygonal area of interest. Data set shortnames, or IDs, as well as version numbers, are located at the top of every NSIDC landing page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    'short_name': 'SNEX17_GPR',\n",
    "    'version': '2','polygon': polygon,\n",
    "    'temporal':temporal,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine how many files exist over this time and area of interest, as well as the average size and total volume of those files\n",
    "\n",
    "We will use the `granule_info` function to query metadata about each data set and associated files using the [Common Metadata Repository (CMR)](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html), which is a high-performance, high-quality, continuously evolving metadata system that catalogs Earth Science data and associated service metadata records. Note that not all NSIDC data can be searched at the file level using CMR, particularly those outside of the NASA DAAC program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 files\n",
      "The total size of all files is 209.20 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'feed': {'updated': '2021-07-13T05:01:31.348Z',\n",
       "  'id': 'https://cmr.earthdata.nasa.gov:443/search/granules.json?short_name=SNEX17_GPR&version=2&polygon=-108.2352445938561%2C38.98556907427165%2C-107.85284607930835%2C38.978765032966244%2C-107.85494925720668%2C39.10596902171742%2C-108.22772795408136%2C39.11294532581687%2C-108.2352445938561%2C38.98556907427165&temporal=2017-01-01T00%3A00%3A00Z%2C2017-12-31T23%3A59%3A59Z',\n",
       "  'title': 'ECHO granule metadata',\n",
       "  'entry': [{'producer_granule_id': 'SnowEx17_GPR_Version2_Week1.csv',\n",
       "    'time_start': '2017-02-08T00:00:00.000Z',\n",
       "    'updated': '2019-11-20T14:19:39.156Z',\n",
       "    'dataset_id': 'SnowEx17 Ground Penetrating Radar V002',\n",
       "    'data_center': 'NSIDC_ECS',\n",
       "    'title': 'SC:SNEX17_GPR.002:167128516',\n",
       "    'coordinate_system': 'GEODETIC',\n",
       "    'day_night_flag': 'UNSPECIFIED',\n",
       "    'time_end': '2017-02-10T23:59:59.000Z',\n",
       "    'id': 'G1657541380-NSIDC_ECS',\n",
       "    'original_format': 'ECHO10',\n",
       "    'granule_size': '57.3195',\n",
       "    'browse_flag': False,\n",
       "    'polygons': [['39.05189 -108.06789 39.04958 -108.07092 39.02644 -108.13422 39.04032 -108.18504 39.0357 -108.2211 39.01719 -108.21534 38.99637 -108.18261 39.00562 -108.11049 39.02413 -108.06225 39.03338 -108.06213 39.02876 -108.08619 39.04264 -108.05301 39.05189 -108.05289 39.0542 -108.06786 39.05189 -108.06789']],\n",
       "    'collection_concept_id': 'C1655875737-NSIDC_ECS',\n",
       "    'online_access_flag': True,\n",
       "    'links': [{'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "      'type': 'text/plain',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://n5eil01u.ecs.nsidc.org/DP1/SNOWEX/SNEX17_GPR.002/2017.02.08/SnowEx17_GPR_Version2_Week1.csv'},\n",
       "     {'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n",
       "      'type': 'text/xml',\n",
       "      'title': '(METADATA)',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://n5eil01u.ecs.nsidc.org/DP1/SNOWEX/SNEX17_GPR.002/2017.02.08/SnowEx17_GPR_Version2_Week1.csv.xml'},\n",
       "     {'inherited': True,\n",
       "      'length': '0.0KB',\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://n5eil01u.ecs.nsidc.org/SNOWEX/SNEX17_GPR.002/'},\n",
       "     {'inherited': True,\n",
       "      'length': '0.0KB',\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://search.earthdata.nasa.gov/search/granules?p=C1655875737-NSIDC_ECS&q=SNEX17_GPR&m=29.76382409255042!-108.823974609375!4!1!0!0%2C2&tl=1558474061!4!!'},\n",
       "     {'inherited': True,\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://doi.org/10.5067/G21LGCNLFSC5'},\n",
       "     {'inherited': True,\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://doi.org/10.5067/G21LGCNLFSC5'}]},\n",
       "   {'producer_granule_id': 'SnowEx17_GPR_Version2_Week2.csv',\n",
       "    'time_start': '2017-02-14T00:00:00.000Z',\n",
       "    'updated': '2019-11-20T14:19:39.156Z',\n",
       "    'dataset_id': 'SnowEx17 Ground Penetrating Radar V002',\n",
       "    'data_center': 'NSIDC_ECS',\n",
       "    'title': 'SC:SNEX17_GPR.002:167128520',\n",
       "    'coordinate_system': 'GEODETIC',\n",
       "    'day_night_flag': 'UNSPECIFIED',\n",
       "    'time_end': '2017-02-17T23:59:59.000Z',\n",
       "    'id': 'G1657541238-NSIDC_ECS',\n",
       "    'original_format': 'ECHO10',\n",
       "    'granule_size': '85.516',\n",
       "    'browse_flag': False,\n",
       "    'polygons': [['39.10738 -107.88943 39.10738 -107.89539 39.0912 -107.95508 39.07271 -108.02372 39.0542 -108.09234 39.04264 -108.16078 39.0357 -108.2113 39.03338 -108.2113 39.0195 -108.20533 39.00099 -108.18454 39.00099 -108.12811 39.00099 -108.08653 39.02644 -108.02094 39.0357 -107.94938 39.02413 -107.93155 39.04726 -107.89867 39.08195 -107.85677 39.10507 -107.86257 39.10969 -107.88644 39.10738 -107.88943']],\n",
       "    'collection_concept_id': 'C1655875737-NSIDC_ECS',\n",
       "    'online_access_flag': True,\n",
       "    'links': [{'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "      'type': 'text/plain',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://n5eil01u.ecs.nsidc.org/DP1/SNOWEX/SNEX17_GPR.002/2017.02.14/SnowEx17_GPR_Version2_Week2.csv'},\n",
       "     {'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n",
       "      'type': 'text/xml',\n",
       "      'title': '(METADATA)',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://n5eil01u.ecs.nsidc.org/DP1/SNOWEX/SNEX17_GPR.002/2017.02.14/SnowEx17_GPR_Version2_Week2.csv.xml'},\n",
       "     {'inherited': True,\n",
       "      'length': '0.0KB',\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://n5eil01u.ecs.nsidc.org/SNOWEX/SNEX17_GPR.002/'},\n",
       "     {'inherited': True,\n",
       "      'length': '0.0KB',\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://search.earthdata.nasa.gov/search/granules?p=C1655875737-NSIDC_ECS&q=SNEX17_GPR&m=29.76382409255042!-108.823974609375!4!1!0!0%2C2&tl=1558474061!4!!'},\n",
       "     {'inherited': True,\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://doi.org/10.5067/G21LGCNLFSC5'},\n",
       "     {'inherited': True,\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://doi.org/10.5067/G21LGCNLFSC5'}]},\n",
       "   {'producer_granule_id': 'SnowEx17_GPR_Version2_Week3.csv',\n",
       "    'time_start': '2017-02-21T00:00:00.000Z',\n",
       "    'updated': '2020-02-18T12:25:16.785Z',\n",
       "    'dataset_id': 'SnowEx17 Ground Penetrating Radar V002',\n",
       "    'data_center': 'NSIDC_ECS',\n",
       "    'title': 'SC:SNEX17_GPR.002:173252482',\n",
       "    'coordinate_system': 'GEODETIC',\n",
       "    'day_night_flag': 'UNSPECIFIED',\n",
       "    'time_end': '2017-02-25T23:59:59.000Z',\n",
       "    'id': 'G1694922459-NSIDC_ECS',\n",
       "    'original_format': 'ECHO10',\n",
       "    'granule_size': '66.3598',\n",
       "    'browse_flag': False,\n",
       "    'polygons': [['39.05189 -108.06789 39.04958 -108.06792 39.03107 -108.08616 39.0195 -108.15531 39.00331 -108.14352 39.00562 -108.11049 39.00562 -108.05349 39.01719 -108.05334 39.02876 -108.02919 39.0542 -108.05586 39.0542 -108.06786 39.05189 -108.06789']],\n",
       "    'collection_concept_id': 'C1655875737-NSIDC_ECS',\n",
       "    'online_access_flag': True,\n",
       "    'links': [{'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "      'type': 'text/plain',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://n5eil01u.ecs.nsidc.org/DP1/SNOWEX/SNEX17_GPR.002/2017.02.21/SnowEx17_GPR_Version2_Week3.csv'},\n",
       "     {'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n",
       "      'type': 'text/xml',\n",
       "      'title': '(METADATA)',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://n5eil01u.ecs.nsidc.org/DP1/SNOWEX/SNEX17_GPR.002/2017.02.21/SnowEx17_GPR_Version2_Week3.csv.xml'},\n",
       "     {'inherited': True,\n",
       "      'length': '0.0KB',\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://n5eil01u.ecs.nsidc.org/SNOWEX/SNEX17_GPR.002/'},\n",
       "     {'inherited': True,\n",
       "      'length': '0.0KB',\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://search.earthdata.nasa.gov/search/granules?p=C1655875737-NSIDC_ECS&q=SNEX17_GPR&m=29.76382409255042!-108.823974609375!4!1!0!0%2C2&tl=1558474061!4!!'},\n",
       "     {'inherited': True,\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://doi.org/10.5067/G21LGCNLFSC5'},\n",
       "     {'inherited': True,\n",
       "      'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#',\n",
       "      'hreflang': 'en-US',\n",
       "      'href': 'https://doi.org/10.5067/G21LGCNLFSC5'}]}]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def search_granules(search_parameters, geojson=None, output_format=\"json\"):\n",
    "    \"\"\"\n",
    "    Performs a granule search with token authentication for restricted results\n",
    "    \n",
    "    :search_parameters: dictionary of CMR search parameters\n",
    "    :token: CMR token needed for restricted search\n",
    "    :geojson: filepath to GeoJSON file for spatial search\n",
    "    :output_format: select format for results https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html#supported-result-formats\n",
    "    \n",
    "    :returns: if hits is greater than 0, search results are returned in chosen output_format, otherwise returns None.\n",
    "    \"\"\"\n",
    "    search_url = \"https://cmr.earthdata.nasa.gov/search/granules\"\n",
    "\n",
    "    \n",
    "    if geojson:\n",
    "        files = {\"shapefile\": (geojson, open(geojson, \"r\"), \"application/geo+json\")}\n",
    "    else:\n",
    "        files = None\n",
    "    \n",
    "    \n",
    "    parameters = {\n",
    "        \"scroll\": \"true\",\n",
    "        \"page_size\": 100,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(f\"{search_url}.{output_format}\", params=parameters, data=search_parameters, files=files)\n",
    "        response.raise_for_status()\n",
    "    except HTTPError as http_err:\n",
    "        print(f\"HTTP Error: {http_error}\")\n",
    "    except Exception as err:\n",
    "        print(f\"Error: {err}\")\n",
    "    \n",
    "    hits = int(response.headers['CMR-Hits'])\n",
    "    if hits > 0:\n",
    "        print(f\"Found {hits} files\")\n",
    "        results = json.loads(response.content)\n",
    "        granules = []\n",
    "        granules.extend(results['feed']['entry'])\n",
    "        granule_sizes = [float(granule['granule_size']) for granule in granules]\n",
    "        print(f\"The total size of all files is {sum(granule_sizes):.2f} MB\")\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Found no hits\")\n",
    "        return\n",
    "\n",
    "search_granules(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Data Access\n",
    "\n",
    "### Option 1: Python script from the data set landing page\n",
    "The [Depths and Snow Pit Data Package Contents](https://snowex-hackweek.github.io/website/tutorials/core-datasets/02_data-package.html) tutorial demonstrates how to access data using the script provided under the \"Download Data\" tab of each NSIDC DAAC data set landing page. Note that you must create a `.netrc` file within the JupyterHub environment, as well ensure you have a Earthdata Login profile, as described in the preliminary work article [here](https://snowex-hackweek.github.io/website/preliminary/earthdata.html#configure-programmatic-access-to-nasa-servers). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Additional data access services: API Access\n",
    "\n",
    "Data can be accessed directly from our HTTPS file system as described in the aforementioned tutorial, or through the NSIDC DAAC's Application Programming Interface (API). \n",
    "\n",
    "What is an API? You can think of an API as a middle man between an application or end-use (in this case, us) and a data provider. Here, the data provider is both the Common Metadata Repository (CMR) housing data information, and NSIDC as the data distributor. These APIs are generally structured as a URL with a base plus individual key-value-pairs separated by ‘&’. This option is beneficial for those of you who want to incorporate data access directly into your visualization and analysis coding workflow, without the need to utilize the NSIDC website. This method is also reproducible and documented to ensure data provenance.\n",
    "\n",
    "\n",
    "This API offers you the ability to order data using specific temporal and spatial filters. These options can be requested in a single access command without the need to script against our data directory structure. See the [programmatic access guide](https://nsidc.org/support/how/how-do-i-programmatically-request-data-services) for more information on API options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the data request API endpoint\n",
    "Programmatic API requests are formatted as HTTPS URLs that contain key-value-pairs specifying the service operations that we specified above. We will first create a string of key-value-pairs from our data dictionary and we'll feed those into our API endpoint. This API endpoint can be executed via command line, a web browser, or in Python below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://n5eil02u.ecs.nsidc.org/egi/request?short_name=SNEX17_GPR&version=2&polygon=-108.2352445938561,38.98556907427165,-107.85284607930835,38.978765032966244,-107.85494925720668,39.10596902171742,-108.22772795408136,39.11294532581687,-108.2352445938561,38.98556907427165&temporal=2017-01-01T00:00:00Z,2017-12-31T23:59:59Z&request_mode=async&agent=NO\n"
     ]
    }
   ],
   "source": [
    "#Set NSIDC data access base URL\n",
    "base_url = 'https://n5eil02u.ecs.nsidc.org/egi/request'\n",
    "\n",
    "#Set the request mode to asynchronous and set page number\n",
    "\n",
    "param_dict['request_mode'] = 'async'\n",
    "param_dict['agent'] = 'NO'\n",
    "\n",
    "param_string = '&'.join(\"{!s}={!r}\".format(k,v) for (k,v) in param_dict.items()) # Convert param_dict to string\n",
    "param_string = param_string.replace(\"'\",\"\") # Remove quotes\n",
    "\n",
    "api_list = [f'{base_url}?{param_string}']\n",
    "api_request = api_list[0]\n",
    "print(api_request) # Print API base URL + request parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Earthdata Login credentials\n",
    "\n",
    "An Earthdata Login account is required to access data from the NSIDC DAAC. If you do not already have an Earthdata Login account, visit http://urs.earthdata.nasa.gov to register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start authenticated session with Earthdata Loging to allow for data downloads:\n",
    "\n",
    "def setup_earthdata_login_auth(endpoint: str='urs.earthdata.nasa.gov'):\n",
    "    netrc_name = \"_netrc\" if system()==\"Windows\" else \".netrc\"\n",
    "    try:\n",
    "        username, _, password = netrc(file=join(expanduser('~'), netrc_name)).authenticators(endpoint)\n",
    "    except (FileNotFoundError, TypeError):\n",
    "        print('Please provide your Earthdata Login credentials for access.')\n",
    "        print('Your info will only be passed to %s and will not be exposed in Jupyter.' % (endpoint))\n",
    "        username = input('Username: ')\n",
    "        password = getpass('Password: ')\n",
    "    manager = request.HTTPPasswordMgrWithDefaultRealm()\n",
    "    manager.add_password(None, endpoint, username, password)\n",
    "    auth = request.HTTPBasicAuthHandler(manager)\n",
    "    jar = CookieJar()\n",
    "    processor = request.HTTPCookieProcessor(jar)\n",
    "    opener = request.build_opener(auth, processor)\n",
    "    request.install_opener(opener)\n",
    "\n",
    "setup_earthdata_login_auth(endpoint=\"urs.earthdata.nasa.gov\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download data\n",
    "\n",
    "Download data using the `requests` library. The data will be downloaded directly to this directory in a new Outputs folder. The progress of each order will be reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order status URL:  https://n5eil02u.ecs.nsidc.org/egi/request/5000001156664\n",
      "Job status is  processing . Trying again.\n",
      "Job status is  complete\n",
      "Zip download URL:  https://n5eil02u.ecs.nsidc.org/esir/5000001156664.zip\n",
      "Beginning download of zipped output...\n",
      "Download is complete.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 39] Directory not empty: '/home/jovyan/website/book/tutorials/nsidc-access/Outputs/167128516'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4e9e425d36ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mrequest_nsidc_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-4e9e425d36ee>\u001b[0m in \u001b[0;36mrequest_nsidc_data\u001b[0;34m(API_request)\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 39] Directory not empty: '/home/jovyan/website/book/tutorials/nsidc-access/Outputs/167128516'"
     ]
    }
   ],
   "source": [
    "def request_nsidc_data(API_request):\n",
    "    \"\"\"\n",
    "    Performs a data customization and access request from NSIDC's API/\n",
    "    Creates an output folder in the working directory if one does not already exist.\n",
    "    \n",
    "    :API_request: NSIDC API endpoint; see https://nsidc.org/support/how/how-do-i-programmatically-request-data-services for more info\n",
    "    on how to configure the API request.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    path = str(os.getcwd() + '/Outputs') # Create an output folder if the folder does not already exist.\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "        \n",
    "    base_url = 'https://n5eil02u.ecs.nsidc.org/egi/request'\n",
    "\n",
    "    \n",
    "    r = request.urlopen(API_request)\n",
    "    esir_root = ET.fromstring(r.read())\n",
    "    orderlist = []   # Look up order ID\n",
    "    for order in esir_root.findall(\"./order/\"):\n",
    "        orderlist.append(order.text)\n",
    "    orderID = orderlist[0]\n",
    "    statusURL = base_url + '/' + orderID # Create status URL\n",
    "    print('Order status URL: ', statusURL)\n",
    "    request_response = request.urlopen(statusURL) # Find order status  \n",
    "    request_root = ET.fromstring(request_response.read())\n",
    "    statuslist = []\n",
    "    for status in request_root.findall(\"./requestStatus/\"):\n",
    "        statuslist.append(status.text)\n",
    "    status = statuslist[0]\n",
    "    while status == 'pending' or status == 'processing': #Continue loop while request is still processing\n",
    "        print('Job status is ', status,'. Trying again.')\n",
    "        time.sleep(10)\n",
    "        loop_response = request.urlopen(statusURL)\n",
    "        loop_root = ET.fromstring(loop_response.read())\n",
    "        statuslist = [] #find status\n",
    "        for status in loop_root.findall(\"./requestStatus/\"):\n",
    "            statuslist.append(status.text)\n",
    "        status = statuslist[0]\n",
    "        if status == 'pending' or status == 'processing':\n",
    "            continue\n",
    "    if status == 'complete_with_errors' or status == 'failed': # Provide complete_with_errors error message:\n",
    "        messagelist = []\n",
    "        for message in loop_root.findall(\"./processInfo/\"):\n",
    "            messagelist.append(message.text)\n",
    "        print('Job status is ', status)\n",
    "        print('error messages:')\n",
    "        pprint(messagelist)\n",
    "    if status == 'complete' or status == 'complete_with_errors':# Download zipped order if status is complete or complete_with_errors\n",
    "        downloadURL = 'https://n5eil02u.ecs.nsidc.org/esir/' + orderID + '.zip'\n",
    "        print('Job status is ', status)\n",
    "        print('Zip download URL: ', downloadURL)\n",
    "        print('Beginning download of zipped output...')\n",
    "        zip_response = request.urlopen(downloadURL)\n",
    "        with zipfile.ZipFile(io.BytesIO(zip_response.read())) as z:\n",
    "            z.extractall(path)\n",
    "        print('Download is complete.')\n",
    "    else: print('Request failed.')\n",
    "    \n",
    "    # Clean up Outputs folder by removing individual granule folders \n",
    "    for root, dirs, files in os.walk(path, topdown=False):\n",
    "        for file in files:\n",
    "            try:\n",
    "                shutil.move(os.path.join(root, file), path)\n",
    "            except OSError:\n",
    "                pass\n",
    "        for name in dirs:\n",
    "            os.rmdir(os.path.join(root, name))\n",
    "    return  \n",
    "\n",
    "request_nsidc_data(api_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Read in SnowEx data and buffer points around Snotel location\n",
    "\n",
    "This SnowEx data set is provided in CSV. A [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/getting_started/overview.html) is used to easily read in data. For these next steps, just one day's worth of data will be selected from this file and the coincident ASO and MODIS data will be selected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowex_path = './Outputs/SnowEx17_GPR_Version2_Week1.csv' # Define local filepath\n",
    "df = pd.read_csv(snowex_path, sep='\\t') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to time values and extract a single day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection date needs to be extracted from the `collection` value and a new dataframe will be generated as a subset of the original based on a single day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df.collection.str.rsplit('_').str[-1].astype(str)\n",
    "df.date = pd.to_datetime(df.date, format=\"%m%d%y\")\n",
    "df = df.sort_values(['date'])\n",
    "df_subset = df[df['date'] == '2017-02-08'] # subset original dataframe and only select this date\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Geopandas dataframe to provide point geometry\n",
    "\n",
    "According to the SnowEx documentation, the data are available in UTM Zone 12N so we'll set to this projection so that we can buffer in meters in the next step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_utm= gpd.GeoDataFrame(df_subset, geometry=gpd.points_from_xy(df_subset.x, df_subset.y), crs='EPSG:32612')\n",
    "gdf_utm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional data imagery services\n",
    "\n",
    "#### NASA Worldview and the Global Browse Imagery Service\n",
    "\n",
    "NASA’s EOSDIS Worldview mapping application provides the capability to interactively browse over 900 global, full-resolution satellite imagery layers and then download the underlying data. Many of the available imagery layers are updated within three hours of observation, essentially showing the entire Earth as it looks “right now.\"\n",
    "\n",
    "According to the [MOD10A1 landing page](https://nsidc.org/data/mod10a1), snow cover imagery layers from this data set are available through NASA Worldview. This layer can be downloaded as various image files including GeoTIFF using the snapshot feature at the top right of the page. This link presents the MOD10A1 NDSI layer over our time and area of interest: https://go.nasa.gov/35CgYMd. \n",
    "\n",
    "Additionally, the NASA Global Browse Imagery Service provides up to date, full resolution imagery for select NSIDC DAAC data sets as web services including WMTS, WMS, KML, and more. These layers can be accessed in GIS applications following guidance on the [GIBS documentation pages](https://wiki.earthdata.nasa.gov/display/GIBS/Geographic+Information+System+%28GIS%29+Usage). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dataframe to Shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the dataframe can be exported as an Esri shapefile for further analysis in GIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_buffer = gdf_buffer.drop(columns=['date'])\n",
    "gdf_buffer.to_file('snow-data-20170208.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
