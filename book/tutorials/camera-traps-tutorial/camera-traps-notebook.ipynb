{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "passing-bargain",
   "metadata": {},
   "source": [
    "# Camera Traps and Snow Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-bangkok",
   "metadata": {},
   "source": [
    "- Catherine Breen, cbreen@uw.edu\n",
    "- Cassie Lumbrazo, lumbraca@uw.edu\n",
    "\n",
    "## What is a camera trap?\n",
    "\n",
    "- A camera trap (sometimes referred to as a remote camera or hunting camera) is similar to a normal camera except they:\n",
    "    - *1) can detect  and take pictures when motion is in their vicinity.*\n",
    "    - *2) can take pictures at consistent intervals at settings preset by the user.*  \n",
    "    - *3) are designed to withstand harsh conditions and to be left up for long periods of time.* \n",
    "- Their potential for snow hydrology is exciting. Consistent daily camera trap photos can be analyzed contiously to form a *time-lapse* of snow conditions at one location. They can operate in sub-freezing temperatures and during storms -- conditions when access with other types of measurements would have been difficult. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-latino",
   "metadata": {},
   "source": [
    "## Camera Traps and SnowEx\n",
    "- Camera traps were installed in both the 2017 and 2020 SnowEx campaigns. \n",
    "- During the 2020 SnowEx field campaign, 30 cameras were installed in Grand Mesa, CO between September and May. \n",
    "- Cameras were installed across a vegetation gradient on a scale of 1 (least vegetation and ) to 9 (most vegetation). Within each vegetation class, there were three sub-classes of snow depths: shallow, intermediate, and deep snow, that were derived from 2017 SnowEx lidar measurements. \n",
    "- 2017 camera trap time-lapse imagery has been submitted to the NSIDC (Raleigh & Lumbrazo 2021). 2020 time-lapse is in progress for submission to the NSIDC with estimation of submission in summer 2021. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-adolescent",
   "metadata": {},
   "source": [
    "### Pulling and visualizing camera trap data\n",
    "\n",
    "We will now pull some time-lapse imagery for one camera from the 2020 SnowEx field campaign. This is camera E9B. We will pull images and display a couple from various times of the winter season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync --no-progress s3://snowex-data/tutorial-data/camera-trap/ /tmp/camera-trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "pil_img = Image(filename='/tmp/camera-trap/WSCT0101.JPG')\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-disposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = Image(filename='/tmp/camera-trap/WSCT0378.JPG')\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = Image(filename='/tmp/camera-trap/WSCT0742.JPG')\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-fence",
   "metadata": {},
   "source": [
    "- What do you notice? Is this an open or closed canopy site? \n",
    "- Can you see the snow rising and falling on the pole? \n",
    "- What are some snow properties that you might be able to measure using these devices? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-samuel",
   "metadata": {},
   "source": [
    "## Applications\n",
    "\n",
    "### Snow Depth\n",
    "\n",
    "Installing snow poles in front of camera trap images can provide low-cost, long-term snow depth timeseries. Using manual and automated methods, one can find the snow depth by finding the difference between the number of pixels in a snow-free image and an image with snow, and converting the difference from pixels to centimeters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-shell",
   "metadata": {},
   "source": [
    "Snow depths from the 2020 SnowEx timelapse imagery have been manually processed with estimation of submission to the NSIDC database in summer 2021 (*in progress* Breen et al. 2021). Below we will explore the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-lodge",
   "metadata": {},
   "source": [
    "#### Step 1: Grab all the pit and camera locations\n",
    "\n",
    "*code credit: Micah Johnson*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-validity",
   "metadata": {},
   "source": [
    "The code block uses geopandas, matplotlib and pandas libraries to look at tabular data on the SnowEx SQL database. We will compare the camera trap locations to the 2020 snow pit locations on the Grand Mesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-pitch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowexsql.db\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import PointData, SiteData\n",
    "from snowexsql.conversions import query_to_geopandas\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the database\n",
    "db_name = 'snow:hackweek@52.32.183.144/snowex'\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "# Grab all the point data that was that was measured with a camera-trap\n",
    "qry = session.query(PointData)\n",
    "qry = qry.filter(PointData.instrument == 'camera-trap')\n",
    "\n",
    "# Convert it to a geopandas df\n",
    "camera_depths = query_to_geopandas(qry, engine)\n",
    "\n",
    "# Grab all the unique pits geometry objects (locations)\n",
    "qry = session.query(SiteData.geom).distinct()\n",
    "pits = query_to_geopandas(qry, engine)\n",
    "\n",
    "# Print out how many of each that we found\n",
    "print(f'Found {len(camera_depths[\"geom\"].unique())} camera trap locations')\n",
    "print(f'Found {len(pits.index)} pit site locations')\n",
    "\n",
    "# End our database session to avoid hanging transactions\n",
    "session.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-julian",
   "metadata": {},
   "source": [
    "#### Step 2: Plot our camera and Pit locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot our pits as triangles\n",
    "ax = pits.plot(marker='^', color='gray', label='Pits')\n",
    "\n",
    "# Plot our cameras as squares\n",
    "ax = camera_depths.plot(ax=ax, color='magenta', marker='s', label='Camera Traps')\n",
    "\n",
    "# Don't use scientific notation on the ticks for utm coords\n",
    "ax.ticklabel_format(style='plain', useOffset=False)\n",
    "ax.set_xlabel('Easting [m]')\n",
    "ax.set_ylabel('Northing [m]')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-export",
   "metadata": {},
   "source": [
    "- What do you notice? Is there overlap between the snow pit and camera trap locations?\n",
    "- How might the two datasets be compared?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upset-raising",
   "metadata": {},
   "source": [
    "#### Step 3: Grab/Plot the Vegetated and Open Camera sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the open site data from the db\n",
    "open_site = 'W1A'\n",
    "veg_site = 'W9A'\n",
    "qry = session.query(PointData).filter(PointData.equipment.contains(open_site))\n",
    "df_open = query_to_geopandas(qry,engine)\n",
    "\n",
    "# Grab the vegetated site from the db\n",
    "qry = session.query(PointData).filter(PointData.equipment.contains(veg_site))\n",
    "df_veg = query_to_geopandas(qry,engine)\n",
    "\n",
    "# Set the date as the index for easy plotting/reading\n",
    "df_open = df_open.set_index('date')\n",
    "df_veg = df_veg.set_index('date')\n",
    "\n",
    "# Plot the 2 datasets by date!\n",
    "ax = df_open['value'].plot(label=f'Open ({open_site})')\n",
    "df_veg['value'].plot(ax=ax, label=f'Vegetated ({veg_site})')\n",
    "\n",
    "# Mess with some labeling to make it look nice\n",
    "ax.legend()\n",
    "ax.set_ylabel('Snow Depth [cm]')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-nature",
   "metadata": {},
   "source": [
    "- What do you notice about the differences between the open and closed canopy site? \n",
    "- What might be some drawbacks to this method? \n",
    "- What would it look like to map and compare all the closed canopy sites to all the open canopy sites? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-religion",
   "metadata": {},
   "source": [
    "## Current and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-notice",
   "metadata": {},
   "source": [
    "### Snow Depth\n",
    "\n",
    "Automated methods to extract snow depth using the Hough Transform (Currier et al. 2017) have been used on this (*in progress* Breen et al. 2021). The available automated and manual codes are available on GitHub: XX. \n",
    "\n",
    "### Other snow properties\n",
    "Camera traps have many more applications for snow. One is using them to improve understanding of snow in trees. Cassie Lumbrazo and the Hydrology Lab at the UW https://www.zooniverse.org/projects/mozerm/snow-spotter have uploaded 1000s of photos in a citizen science project to increase labeling efforts for snow in trees and provide educational opportunities to learn about snow.\n",
    "\n",
    "- How else might you use these images to advance SnowEx and snow hydrology?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-monitoring",
   "metadata": {},
   "source": [
    "**Thank you for attending this tutorial! We look forward to see what you will find in these datasets!**\n",
    "\n",
    "*Acknowledgements: Anthony Arendt, Scott Henderson, Carrie Vuyovich, Ryan Currier, Megan Mason, Micah Johhnson*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
